getPdistrem(drNull)
parboot(drNull, getPdistrem, nsim = 25, report = 1)
##
getPdistrem <- function(drNull) {
d <- backTransform(drNull@estimates@estimates$rem)@estimate
sig <- backTransform(drNull@estimates@estimates$dist)@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
er <- sqrt(ea / pi) # effective radius
p <- ea / (pi*400^2) #detection probability
Pd <- p*d
return(Pd)
}
parboot(drNull, getPdistrem, nsim = 25, report = 1)
##
getPdistrem <- function(x) {
d <- backTransform(x@estimates@estimates$rem)@estimate
sig <- backTransform(x@estimates@estimates$dist)@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
er <- sqrt(ea / pi) # effective radius
p <- ea / (pi*400^2) #detection probability
Pd <- p*d
return(Pd)
}
parboot(drNull, getPdistrem, nsim = 25, report = 1, method = "BFGS")
parboot
showMethods(parboot)
parboot(drNull, getPdistrem, nsim = 25, report = 1, method = "BFGS")
parboot(drNull, getPdistrem, nsim = 25, report = 1)
parboot(drNull, getPdistrem, nsim = 2, report = 1)
parboot()
parboot
parboot(hnNull, getPdistrem, nsim = 25, report = 1)
parboot(drNull, getPdistrem, nsim = 25, report = 1)
parboot(drNull, getPdistrem, nsim = 25, report = 1, control = list(method = "BFGS"))
parboot(drNull, getPdistrem, nsim = 25, report = 1)
getPdistrem(drNull)
testm2 <- nonparboot(drNull, B = 20)
predict(drNull)
predict(drNull, type = "det")
predict(drNull, type = "rem")
library(tidyverse)
library(readxl)
library(lubridate)
library(suncalc)
library(ggpmisc)
library(unmarked)
library(AICcmodavg)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22.csv")
names(surveyData)[1] <- 'surveyEvent'
#surveyData$Count_Date <- mdy(surveyData$Count_Date)
surveyData$Count_Date <- mdy(surveyData$Survey_Date)
#surveyData$Start_Time <- hms(surveyData$Start_Time)
surveyData$Start_Time <- hms(surveyData$Survey_Time)
surveyData$Site_ID <- factor(surveyData$Site_ID)
surveyData$Observer <- factor(surveyData$Observer)
surveyData$Sky_Code <- factor(surveyData$Sky_Code, levels = c("0","1","2","3","4"),
labels = c("Clear","Partly cloudy","Mostly cloudy","Fog or smoke","Drizzle"))
surveyData$Sex <- factor(surveyData$Sex, levels = c("M","F","U"), labels = c("Male","Female","Unknown"))
surveyData$Age <- factor(surveyData$Age, levels = c("A", "J"), labels = c("Adult", "Juvenile"))
surveyData$`Distance Band` <- factor(surveyData$`Distance Band`)
names(surveyData)[19] <- 'distanceBand'
surveyData$Interval_1 <- ifelse(surveyData$Interval_1 == "X", NA, surveyData$Interval_1)
surveyData$Interval_2 <- ifelse(surveyData$Interval_2 == "X", NA, surveyData$Interval_2)
surveyData$Interval_3 <- ifelse(surveyData$Interval_3 == "X", NA, surveyData$Interval_3)
surveyData$Interval_4 <- ifelse(surveyData$Interval_4 == "X", NA, surveyData$Interval_4)
surveyData$Interval_1 <- factor(surveyData$Interval_1, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_2 <- factor(surveyData$Interval_2, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_3 <- factor(surveyData$Interval_3, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_4 <- factor(surveyData$Interval_4, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$dayOfYear <- yday(surveyData$Count_Date) # create a day-of-year variable for analysis
## Add a "first detected by..." column to survey data:
surveyData <-
surveyData %>%
filter(!is.na(Sex)) %>%
select(Sex, Lark_ID, Interval_1, Interval_2, Interval_3, Interval_4) %>%
pivot_longer(., cols = 3:6, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID, Sex) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(detection)) %>%
right_join(., surveyData, by = 'Lark_ID', keep = F) %>%
select(!(Sex.x)) %>%
rename(Sex = Sex.y)
## Add a "first detected interval" column
surveyData <-
surveyData %>%
filter(!is.na(Sex)) %>%
select(Sex, Lark_ID, Interval_1, Interval_2, Interval_3, Interval_4) %>%
pivot_longer(., cols = 3:6, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID, Sex) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(interval)) %>%
mutate(firstInterval = ifelse(firstDet == "Interval_1",1,
ifelse(firstDet == "Interval_2", 2,
ifelse(firstDet == "Interval_3", 3,
ifelse(firstDet == "Interval_4", 4, NA))))) %>%
right_join(., surveyData, by = 'Lark_ID', keep = F) %>%
select(!(Sex.x)) %>%
select(!firstDet.x) %>%
rename(firstDet = firstDet.y, Sex = Sex.y)
# Get sunrise times to look at effect of survey timing in detections,
# here using the Corvallis airport as the location. We could calculate
# sunrise based on the lat/long of each survey point, but they are
# all going to have roughly the same sunrise so for ease I'm simply estimating
# sunrise at a single, central location.
# calculate sunrise times at Corvallis Airport on each survey date.
sunriseTimes <- getSunlightTimes(date = surveyData$Count_Date, lat = 44.50, lon = -123.28,
keep = c("sunrise"), tz="America/Los_Angeles")
#create a new variable in surveyData that has sunrise matched to the survey point.
#careful, here, because there is no matching function (i.e., this only works if the
#two data frames are sorted in the same order. This should be the case unless you
#sort one after calling this function).
surveyData$sunrise <- sunriseTimes$sunrise
#subtract the two times to get decimal hours after sunrise.
surveyData$mas <- 60*((surveyData$Start_Time@hour + surveyData$Start_Time@minute/60) -
(hour(surveyData$sunrise) + minute(surveyData$sunrise)/60))
#clean up
rm(sunriseTimes)
# Read in survey location and habitat data
habitatData <- read_csv("tbl_survey_locations_exported_09_26_2022_pct_suitable_2021.csv")
habitatData$Site_ID <- factor(habitatData$Site_ID)
habitatAndSurveyData <-
habitatData %>%
select(Site_ID,ln_UTM1083,lt_UTM1083,ln_WGS84,lt_WGS84, pct_suitable_2021) %>%
right_join(.,surveyData, by = 'Site_ID', keep = F)
habitatAndSurveyData$Site_ID <- factor(habitatAndSurveyData$Site_ID)
habitatAndSurveyData$Observer <- factor(habitatAndSurveyData$Observer)
# Make encounter histories for detected birds across intervals
surveyData$encounterHistory <- paste(if_else(surveyData$Interval_1 == "None", 0,1),
if_else(surveyData$Interval_2 == "None", 0,1),
if_else(surveyData$Interval_3 == "None", 0,1),
if_else(surveyData$Interval_4 == "None", 0,1),
sep = "")
dists <-
surveyData %>%
group_by(Site_ID) %>%
mutate(distance = ifelse(distanceBand == 1, 12.5,
ifelse(distanceBand == 2, 61,
ifelse(distanceBand == 3, 150,
ifelse(distanceBand == 4, 300, NA))))) %>%
select(Site_ID, distance, Sex, firstDet) %>%
filter(!is.na(distance), firstDet == "Singing", Sex == "Male")
## Note here that we need the "as.data.frame" argument because 'dists' is a tidyverse tibble,
## and unmarked doesn't seem to like tibbles. This forces it into a standard R data frame.
yDat <- formatDistData(distData = as.data.frame(dists), distCol = "distance", transectNameCol = "Site_ID",
dist.breaks = c(0,25,100,200,400))
## Create a data frame of site-level covariates.
covs <-
surveyData %>%
group_by(Site_ID) %>%
summarise(site = first(Site_ID),
observer = first(Observer),
temp = first(Temp),
avgNoise = first(Avg_Noise),
dayOfYear = first (dayOfYear),
mas = first(mas))
umf <- unmarkedFrameDS(y = as.matrix(yDat), siteCovs = as.data.frame(covs),
survey = "point", dist.breaks = c(0,25,100,200,400), unitsIn = "m")
summary(umf)
hist(umf, freq = TRUE, xlab = "Distance (m)", main = "Streaked Horned Lark detections 2022", cex.lab = 0.8, cex.axis = 0.8)
encounters <-
surveyData %>%
group_by(Site_ID) %>%
mutate(interval1 = ifelse(firstInterval == 1 & Sex == "Male" & firstDet == "Singing", 1, 0),
interval2 = ifelse(firstInterval == 2 & Sex == "Male" & firstDet == "Singing", 1, 0),
interval3 = ifelse(firstInterval == 3 & Sex == "Male" & firstDet == "Singing", 1, 0),
interval4 = ifelse(firstInterval == 4 & Sex == "Male" & firstDet == "Singing", 1, 0)) %>%
select(Site_ID, interval1, interval2, interval3, interval4, Sex, firstDet) %>%
group_by(Site_ID) %>%
summarise(interval1 = sum(interval1), # this model wants summed # of birds per interval
interval2 = sum(interval2), # and has to match the distance data
interval3 = sum(interval3),
interval4 = sum(interval4))
yRemoval <- matrix(nrow = 214, ncol = 4)
rownames(yRemoval) <- encounters$Site_ID
yRemoval <- cbind(encounters[,2:5])
yRemoval[is.na(yRemoval)] <- 0
## Create a new variable called 'distance', which translates the distance_band information into the midpoint of the distance.
## Then remove all other variables.
## THIS INCLUDES ONLY SINGING MALES ##
distsRemoval <-
surveyData %>%
group_by(Site_ID) %>%
mutate(distance = ifelse(distanceBand == 1, 12.5,
ifelse(distanceBand == 2, 61,
ifelse(distanceBand == 3, 150,
ifelse(distanceBand == 4, 300, NA))))) %>%
select(Site_ID, distance, Sex, firstDet) %>%
filter(!is.na(distance), firstDet == "Singing", Sex == "Male")
## Note here that we need the "as.data.frame" argument because 'dists' is a tidyverse tibble,
## and unmarked doesn't seem to like tibbles. This forces it into a standard R data frame.
yDatDistance <- formatDistData(distData = as.data.frame(distsRemoval), distCol = "distance", transectNameCol = "Site_ID",
dist.breaks = c(0,25,100,200,400))
umfDR <- unmarkedFrameGDR(yDistance = as.matrix(yDatDistance), yRemoval = as.matrix(yRemoval), numPrimary = 1,
siteCovs = covs, dist.breaks = c(0,25,100,200,400), unitsIn = "m")
summary(umfDR)
drNull <- gdistremoval(lambdaformula = ~1, phiformula = ~1, removalformula = ~1,
distanceformula = ~1, data = umfDR, keyfun = "halfnorm",
output = "density", unitsOut = "kmsq", mixture = "ZIP")
summary(drNull)
##
getPdistrem <- function(x) {
d <- backTransform(x@estimates@estimates$rem)@estimate
sig <- backTransform(x@estimates@estimates$dist)@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
er <- sqrt(ea / pi) # effective radius
p <- ea / (pi*400^2) #detection probability
Pd <- p*d
return(Pd)
}
getPdistrem(drNull)
parboot(drNull, getPdistrem, nsim = 25, report = 1)
log(0.0169)
exp(-4.080442)
##
getPdistrem <- function(x) {
d <- backTransform(x@estimates@estimates$rem)@estimate
sig <- backTransform(x@estimates@estimates$dist)@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
er <- sqrt(ea / pi) # effective radius
p <- ea / (pi*400^2) #detection probability
Pd <- log(p*d)
return(Pd)
}
getPdistrem(drNull)
parboot(drNull, getPdistrem, nsim = 25, report = 1)
##
getPdistrem <- function(x) {
d <- backTransform(x@estimates@estimates$rem)@estimate
sig <- backTransform(x@estimates@estimates$dist)@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
er <- sqrt(ea / pi) # effective radius
p <- ea / (pi*400^2) #detection probability
Pd <- p*d
return(Pd)
}
getPdistrem(drNull)
library(tidyverse)
library(readxl)
library(lubridate)
library(suncalc)
library(ggpmisc)
library(unmarked)
library(AICcmodavg)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22.csv")
names(surveyData)[1] <- 'surveyEvent'
#surveyData$Count_Date <- mdy(surveyData$Count_Date)
surveyData$Count_Date <- mdy(surveyData$Survey_Date)
#surveyData$Start_Time <- hms(surveyData$Start_Time)
surveyData$Start_Time <- hms(surveyData$Survey_Time)
surveyData$Site_ID <- factor(surveyData$Site_ID)
surveyData$Observer <- factor(surveyData$Observer)
surveyData$Sky_Code <- factor(surveyData$Sky_Code, levels = c("0","1","2","3","4"),
labels = c("Clear","Partly cloudy","Mostly cloudy","Fog or smoke","Drizzle"))
surveyData$Sex <- factor(surveyData$Sex, levels = c("M","F","U"), labels = c("Male","Female","Unknown"))
surveyData$Age <- factor(surveyData$Age, levels = c("A", "J"), labels = c("Adult", "Juvenile"))
surveyData$`Distance Band` <- factor(surveyData$`Distance Band`)
names(surveyData)[19] <- 'distanceBand'
surveyData$Interval_1 <- ifelse(surveyData$Interval_1 == "X", NA, surveyData$Interval_1)
surveyData$Interval_2 <- ifelse(surveyData$Interval_2 == "X", NA, surveyData$Interval_2)
surveyData$Interval_3 <- ifelse(surveyData$Interval_3 == "X", NA, surveyData$Interval_3)
surveyData$Interval_4 <- ifelse(surveyData$Interval_4 == "X", NA, surveyData$Interval_4)
surveyData$Interval_1 <- factor(surveyData$Interval_1, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_2 <- factor(surveyData$Interval_2, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_3 <- factor(surveyData$Interval_3, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_4 <- factor(surveyData$Interval_4, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$dayOfYear <- yday(surveyData$Count_Date) # create a day-of-year variable for analysis
## Add a "first detected by..." column to survey data:
surveyData <-
surveyData %>%
filter(!is.na(Sex)) %>%
select(Sex, Lark_ID, Interval_1, Interval_2, Interval_3, Interval_4) %>%
pivot_longer(., cols = 3:6, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID, Sex) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(detection)) %>%
right_join(., surveyData, by = 'Lark_ID', keep = F) %>%
select(!(Sex.x)) %>%
rename(Sex = Sex.y)
## Add a "first detected interval" column
surveyData <-
surveyData %>%
filter(!is.na(Sex)) %>%
select(Sex, Lark_ID, Interval_1, Interval_2, Interval_3, Interval_4) %>%
pivot_longer(., cols = 3:6, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID, Sex) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(interval)) %>%
mutate(firstInterval = ifelse(firstDet == "Interval_1",1,
ifelse(firstDet == "Interval_2", 2,
ifelse(firstDet == "Interval_3", 3,
ifelse(firstDet == "Interval_4", 4, NA))))) %>%
right_join(., surveyData, by = 'Lark_ID', keep = F) %>%
select(!(Sex.x)) %>%
select(!firstDet.x) %>%
rename(firstDet = firstDet.y, Sex = Sex.y)
# Get sunrise times to look at effect of survey timing in detections,
# here using the Corvallis airport as the location. We could calculate
# sunrise based on the lat/long of each survey point, but they are
# all going to have roughly the same sunrise so for ease I'm simply estimating
# sunrise at a single, central location.
# calculate sunrise times at Corvallis Airport on each survey date.
sunriseTimes <- getSunlightTimes(date = surveyData$Count_Date, lat = 44.50, lon = -123.28,
keep = c("sunrise"), tz="America/Los_Angeles")
#create a new variable in surveyData that has sunrise matched to the survey point.
#careful, here, because there is no matching function (i.e., this only works if the
#two data frames are sorted in the same order. This should be the case unless you
#sort one after calling this function).
surveyData$sunrise <- sunriseTimes$sunrise
#subtract the two times to get decimal hours after sunrise.
surveyData$mas <- 60*((surveyData$Start_Time@hour + surveyData$Start_Time@minute/60) -
(hour(surveyData$sunrise) + minute(surveyData$sunrise)/60))
#clean up
rm(sunriseTimes)
# Read in survey location and habitat data
habitatData <- read_csv("tbl_survey_locations_exported_09_26_2022_pct_suitable_2021.csv")
habitatData$Site_ID <- factor(habitatData$Site_ID)
habitatAndSurveyData <-
habitatData %>%
select(Site_ID,ln_UTM1083,lt_UTM1083,ln_WGS84,lt_WGS84, pct_suitable_2021) %>%
right_join(.,surveyData, by = 'Site_ID', keep = F)
habitatAndSurveyData$Site_ID <- factor(habitatAndSurveyData$Site_ID)
habitatAndSurveyData$Observer <- factor(habitatAndSurveyData$Observer)
# Make encounter histories for detected birds across intervals
surveyData$encounterHistory <- paste(if_else(surveyData$Interval_1 == "None", 0,1),
if_else(surveyData$Interval_2 == "None", 0,1),
if_else(surveyData$Interval_3 == "None", 0,1),
if_else(surveyData$Interval_4 == "None", 0,1),
sep = "")
dists <-
surveyData %>%
group_by(Site_ID) %>%
mutate(distance = ifelse(distanceBand == 1, 12.5,
ifelse(distanceBand == 2, 61,
ifelse(distanceBand == 3, 150,
ifelse(distanceBand == 4, 300, NA))))) %>%
select(Site_ID, distance, Sex, firstDet) %>%
filter(!is.na(distance), firstDet == "Singing", Sex == "Male")
rm(linetran)
rm(dists)
## Prediction and plotting
backTransform(linearComb(hnDay['det'], c(1, min(covs$dayOfYear))))@estimate
## Create a new variable called 'distance', which translates the distance_band information into the midpoint of the distance.
## Then remove all other variables.
## THIS EXCLUDES ALL NON-SINGING MALES ##
dists <-
surveyData %>%
group_by(Site_ID) %>%
mutate(distance = ifelse(distanceBand == 1, 12.5,
ifelse(distanceBand == 2, 61,
ifelse(distanceBand == 3, 150,
ifelse(distanceBand == 4, 300, NA))))) %>%
select(Site_ID, distance, Sex, firstDet) %>%
filter(!is.na(distance), firstDet == "Singing", Sex == "Male")
## Note here that we need the "as.data.frame" argument because 'dists' is a tidyverse tibble,
## and unmarked doesn't seem to like tibbles. This forces it into a standard R data frame.
yDat <- formatDistData(distData = as.data.frame(dists), distCol = "distance", transectNameCol = "Site_ID",
dist.breaks = c(0,25,100,200,400))
## Create a data frame of site-level covariates.
covs <-
surveyData %>%
group_by(Site_ID) %>%
summarise(site = first(Site_ID),
observer = first(Observer),
temp = first(Temp),
avgNoise = first(Avg_Noise),
dayOfYear = first (dayOfYear),
mas = first(mas))
umf <- unmarkedFrameDS(y = as.matrix(yDat), siteCovs = as.data.frame(covs),
survey = "point", dist.breaks = c(0,25,100,200,400), unitsIn = "m")
# Fitting models.
# Half-normal, null
hnNull <- distsamp(~1~1, umf, keyfun = "halfnorm", output = "density", unitsOut = "kmsq")
# Half-normal, Day of year
hnDay <- distsamp(~dayOfYear ~1, data = umf, keyfun = "halfnorm", output = "density", unitsOut = "kmsq")
## Prediction and plotting
backTransform(linearComb(hnDay['det'], c(1, min(covs$dayOfYear))))@estimate
## = 110.326
## Sigma for last day of year:
backTransform(linearComb(hnDay['det'], c(1, max(covs$dayOfYear))))@estimate
par(mfrow=c(1, 2))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob. on first day of surveys", cex.lab=0.7,
cex.axis=0.7, las=1)
hist(hn_Null, xlab="Distance (m)", ylab="Probability density", main="",
ylim=c(0, 0.1), cex.lab=0.7, cex.axis=0.7, las=1)
hist(hnNull, xlab="Distance (m)", ylab="Probability density", main="",
ylim=c(0, 0.1), cex.lab=0.7, cex.axis=0.7, las=1)
plot(function(x) dxhn(x, sigma=110.3216), 0, 20, add=TRUE, col="blue")
plot(function(x) dxhn(x, sigma=946.94998), 0, 20, add=TRUE, col="green")
legend('topright', c("Day = first", "Null", "Day = last"),
col=c("blue", "black", "green"), lty=1, cex=0.4)
par(mfrow=c(1, 2))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob. on first day of surveys", cex.lab=0.7,
cex.axis=0.7, las=1)
hist(hnNull, xlab="Distance (m)", ylab="Probability density", main="",
ylim=c(0, 0.1), cex.lab=0.7, cex.axis=0.7, las=1)
plot(function(x) dxhn(x, sigma=110.3216), 0, 400, add=TRUE, col="blue")
plot(function(x) dxhn(x, sigma=946.94998), 0, 400, add=TRUE, col="green")
legend('topright', c("Day = first", "Null", "Day = last"),
col=c("blue", "black", "green"), lty=1, cex=0.4)
par(mfrow=c(1, 2))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob. on first day of surveys", cex.lab=0.7,
cex.axis=0.7, las=1)
hist(hnNull, xlab="Distance (m)", ylab="Probability density", main="",
ylim=c(0, 0.1), cex.lab=0.7, cex.axis=0.7, las=1)
plot(function(x) dxhn(x, sigma=110.3216), 0, 400, add=TRUE, col="blue")
plot(function(x) dxhn(x, sigma=946.94998), 0, 400, add=TRUE, col="green")
legend('topright', c("Day = first", "Null", "Day = last"),
col=c("blue", "black", "green"), lty=1, cex=0.8)
par(mfrow=c(1, 2))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob. on first day of surveys", cex.lab=0.7,
cex.axis=0.7, las=1)
hist(hnNull, xlab="Distance (m)", ylab="Probability density", main="",
ylim=c(0, 0.1), cex.lab=0.7, cex.axis=0.7, las=1)
plot(function(x) dxhn(x, sigma=110.3216), 0, 400, add=TRUE, col="blue")
plot(function(x) dxhn(x, sigma=946.94998), 0, 400, add=TRUE, col="green")
legend('topright', c("Day = first", "Null", "Day = last"),
col=c("blue", "black", "green"), lty=1, cex=0.6)
par(mfrow=c(1, 2))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob. on first day of surveys", cex.lab=0.7,
cex.axis=0.7, las=1)
plot(function(x) gxhn(x, sigma=46.94988), 0, 400, xlab="Distance (m)",
ylab="Detection prob. on last day of surveys", cex.lab=0.7,
cex.axis=0.7, las=1)
par(mfrow=c(1, 1))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob.", cex.lab=0.7,
cex.axis=0.7, las=1, col = "green")
plot(function(x) gxhn(x, sigma=46.94988), 0, 400, add = TRUE, col = "blue")
## = 46.94998
## Sigma for the median day:
backTransform(linearComb(hnDay['det'], c(1, median(covs$dayOfYear))))@estimate
par(mfrow=c(1, 1))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob.", cex.lab=0.7,
cex.axis=0.7, las=1, col = "green")
plot(function(x) gxhn(x, sigma=46.94988), 0, 400, add = TRUE, col = "blue")
plot(function(x) gxhn(x, sigma=68.06919), 0, 400, add = TRUE, col = "black")
par(mfrow=c(1, 1))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob.", cex.lab=0.7,
cex.axis=0.7, las=1, col = "green")
plot(function(x) gxhn(x, sigma=46.94988), 0, 400, add = TRUE, col = "blue")
plot(function(x) gxhn(x, sigma=68.06919), 0, 400, add = TRUE, col = "black")
legend('topright', c("First day of surveys", "Last day of surveys", "Median day of surveys"),
col=c("green", "blue", "black"), lty=1, cex=0.4)
par(mfrow=c(1, 1))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob.", cex.lab=0.7,
cex.axis=0.7, las=1, col = "green")
plot(function(x) gxhn(x, sigma=46.94988), 0, 400, add = TRUE, col = "blue")
plot(function(x) gxhn(x, sigma=68.06919), 0, 400, add = TRUE, col = "black")
legend('topright', c("First day of surveys", "Last day of surveys", "Median day of surveys"),
col=c("green", "blue", "black"), lty=1, cex=0.6)
par(mfrow=c(1, 1))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection prob.", cex.lab=0.7,
cex.axis=0.7, las=1, col = "green")
plot(function(x) gxhn(x, sigma=46.94988), 0, 400, add = TRUE, col = "blue")
plot(function(x) gxhn(x, sigma=68.06919), 0, 400, add = TRUE, col = "black")
legend('topright', c("First day of surveys", "Last day of surveys", "Median day of surveys"),
col=c("green", "blue", "black"), lty=1, cex=0.8)
par(mfrow=c(1, 1))
plot(function(x) gxhn(x, sigma=110.3216), 0, 400, xlab="Distance (m)",
ylab="Detection probability", cex.lab=1,
cex.axis=0.7, las=1, col = "green")
plot(function(x) gxhn(x, sigma=46.94988), 0, 400, add = TRUE, col = "blue")
plot(function(x) gxhn(x, sigma=68.06919), 0, 400, add = TRUE, col = "black")
legend('topright', c("First day of surveys", "Last day of surveys", "Median day of surveys"),
col=c("green", "blue", "black"), lty=1, cex=0.8)
knitr::opts_chunk$set(echo = TRUE)
(pb <- parboot(hnDay, fitstats, nsim=25, report=NULL))
# Goodness of fit
fitstats <- function(hnDay) {
observed <- getY(hnDay@data)
expected <- fitted(hnDay)
resids <- residuals(hnDay)
sse <- sum(resids^2)
chisq <- sum((observed - expected)^2 / expected)
freeTuke <- sum((sqrt(observed) - sqrt(expected))^2)
out <- c(SSE=sse, Chisq=chisq, freemanTukey=freeTuke)
return(out)
}
(pb <- parboot(hnDay, fitstats, nsim=25, report=NULL))
(pb <- parboot(hnDay, fitstats, nsim=25, report=50))
getPcovs <- function(hnDay) {
sig <- backTransform(linearComb(hnDay['det'], c(1, median(covs$dayOfYear))))@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
er <- sqrt(ea / pi) # effective radius
p <- ea / (pi*400^2) #detection probability
out <- c(p = p , er = er)
return(out)
}
parboot(hnDay, getPcovs, nsim = 25, report = 1)
getPcovs()
getPcovs(hnDay)
