c("Calling", "Singing", "Visual"))
surveyData24$Interval_20 <- factor(surveyData24$Interval_20, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData24$Interval_21 <- factor(surveyData24$Interval_21, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData24$Interval_22 <- factor(surveyData24$Interval_22, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData24$Interval_23 <- factor(surveyData24$Interval_23, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData24$Interval_24 <- factor(surveyData24$Interval_24, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
## Add a "first detected by..." column to survey data:
surveyData24 <-
surveyData24 %>%
pivot_longer(., cols = 7:30, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(detection)) %>%
right_join(., surveyData24, by = 'Lark_ID', keep = F)
## Add a "first interval detected..." column to survey data:
surveyData24 <-
surveyData24 %>%
pivot_longer(., cols = 8:31, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(interval)) %>%
mutate(firstInterval = ifelse(firstDet == "Interval_1",1,
ifelse(firstDet == "Interval_2", 2,
ifelse(firstDet == "Interval_3", 3,
ifelse(firstDet == "Interval_4", 4,
ifelse(firstDet == "Interval_5", 5,
ifelse(firstDet == "Interval_6", 6,
ifelse(firstDet == "Interval_7", 7,
ifelse(firstDet == "Interval_8", 8,
ifelse(firstDet == "Interval_9", 9,
ifelse(firstDet == "Interval_10", 10,
ifelse(firstDet == "Interval_11", 11,
ifelse(firstDet == "Interval_12", 12,
ifelse(firstDet == "Interval_13", 13,
ifelse(firstDet == "Interval_14", 14,
ifelse(firstDet == "Interval_15", 15,
ifelse(firstDet == "Interval_16", 16,
ifelse(firstDet == "Interval_17", 17,
ifelse(firstDet == "Interval_18", 18,
ifelse(firstDet == "Interval_19", 19,
ifelse(firstDet == "Interval_20", 20,
ifelse(firstDet == "Interval_21", 21,
ifelse(firstDet == "Interval_22", 22,
ifelse(firstDet == "Interval_23", 23,
ifelse(firstDet == "Interval_24", 24,NA)))))))))))))))))))))))))%>%
right_join(., surveyData24, by = 'Lark_ID', keep = F) %>%
select(!(firstDet.x)) %>%
rename(firstDet = firstDet.y)
#2025
## This file reads in with ~1000 extra rows, all blank, unless n_max is specified
surveyData25 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv",n_max = 159)
surveyData25 <-
surveyData25 %>%
select(unique_ID, Survey_Date,Survey_Time,Lark_ID, Min_1,Min_2,Min_3,Min_4,Min_5,Min_6,
Min_7,Min_8,Min_9,Min_10,Min_11,Min_12) %>%
mutate(site = factor(unique_ID)) %>%
select(-unique_ID)
surveyData25$Count_Date <- mdy(surveyData25$Survey_Date)
surveyData25$Start_Time <- hms(surveyData25$Survey_Time)
surveyData25$dayOfYear <- yday(surveyData25$Count_Date) # create a day-of-year variable for analysis
surveyData25$surveyYear <- year(surveyData25$Count_Date)
surveyData25 <-
surveyData25 %>%
select(-Survey_Date, -Survey_Time)
surveyData25$Interval_1 <- ifelse(surveyData25$Min_1 == "X", NA, surveyData25$Min_1)
surveyData25$Interval_2 <- ifelse(surveyData25$Min_2 == "X", NA, surveyData25$Min_2)
surveyData25$Interval_3 <- ifelse(surveyData25$Min_3 == "X", NA, surveyData25$Min_3)
surveyData25$Interval_4 <- ifelse(surveyData25$Min_4 == "X", NA, surveyData25$Min_4)
surveyData25$Interval_5 <- ifelse(surveyData25$Min_5 == "X", NA, surveyData25$Min_5)
surveyData25$Interval_6 <- ifelse(surveyData25$Min_6 == "X", NA, surveyData25$Min_6)
surveyData25$Interval_7 <- ifelse(surveyData25$Min_7 == "X", NA, surveyData25$Min_7)
surveyData25$Interval_8 <- ifelse(surveyData25$Min_8 == "X", NA, surveyData25$Min_8)
surveyData25$Interval_9 <- ifelse(surveyData25$Min_9 == "X", NA, surveyData25$Min_9)
surveyData25$Interval_10 <- ifelse(surveyData25$Min_10 == "X", NA, surveyData25$Min_10)
surveyData25$Interval_11 <- ifelse(surveyData25$Min_11 == "X", NA, surveyData25$Min_11)
surveyData25$Interval_12 <- ifelse(surveyData25$Min_12 == "X", NA, surveyData25$Min_12)
surveyData25 <-
surveyData25 %>%
select(-Min_1,-Min_2,-Min_3, -Min_4,-Min_5,
-Min_6,-Min_7,-Min_8, -Min_9, -Min_10,
-Min_11, -Min_12)
surveyData25$Interval_1 <- factor(surveyData25$Interval_1, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_2 <- factor(surveyData25$Interval_2, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_3 <- factor(surveyData25$Interval_3, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_4 <- factor(surveyData25$Interval_4, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_5 <- factor(surveyData25$Interval_5, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_6 <- factor(surveyData25$Interval_6, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_7 <- factor(surveyData25$Interval_7, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_8 <- factor(surveyData25$Interval_8, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_9 <- factor(surveyData25$Interval_9, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_10 <- factor(surveyData25$Interval_10, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_11 <- factor(surveyData25$Interval_11, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_12 <- factor(surveyData25$Interval_12, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
## Add a "first detected by..." column to survey data:
surveyData25 <-
surveyData25 %>%
pivot_longer(., cols = 7:18, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(detection)) %>%
right_join(., surveyData25, by = 'Lark_ID', keep = F)
## Add a "first interval detected..." column to survey data:
surveyData25 <-
surveyData25 %>%
pivot_longer(., cols = 8:19, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(interval)) %>%
mutate(firstInterval = ifelse(firstDet == "Interval_1",1,
ifelse(firstDet == "Interval_2", 2,
ifelse(firstDet == "Interval_3", 3,
ifelse(firstDet == "Interval_4", 4,
ifelse(firstDet == "Interval_5", 5,
ifelse(firstDet == "Interval_6", 6,
ifelse(firstDet == "Interval_7", 7,
ifelse(firstDet == "Interval_8", 8,
ifelse(firstDet == "Interval_9", 9,
ifelse(firstDet == "Interval_10", 10,
ifelse(firstDet == "Interval_11", 11,
ifelse(firstDet == "Interval_12", 12,NA)))))))))))))%>%
right_join(., surveyData25, by = 'Lark_ID', keep = F) %>%
select(!(firstDet.x)) %>%
rename(firstDet = firstDet.y)
#Encounter histories
## 2023
surveyData23 <-
surveyData23 %>%
mutate(Interval_1 = ifelse(firstInterval == 1, 1, 0),
Interval_2 = ifelse(firstInterval == 2, 1, 0),
Interval_3 = ifelse(firstInterval == 3, 1, 0),
Interval_4 = ifelse(firstInterval == 4, 1, 0))
### Change NA to zero for counts with no detections
#### 2023
surveyData23 <-
surveyData23 %>%
mutate(Interval_1 = ifelse(is.na(firstInterval == TRUE), 0, Interval_1),
Interval_2 = ifelse(is.na(firstInterval == TRUE), 0, Interval_2),
Interval_3 = ifelse(is.na(firstInterval == TRUE), 0, Interval_3),
Interval_4 = ifelse(is.na(firstInterval == TRUE), 0, Interval_4))
## 2024
surveyData24 <-
surveyData24 %>%
mutate(Interval_1 = ifelse(firstInterval == 1, 1, 0),
Interval_2 = ifelse(firstInterval == 2, 1, 0),
Interval_3 = ifelse(firstInterval == 3, 1, 0),
Interval_4 = ifelse(firstInterval == 4, 1, 0),
Interval_5 = ifelse(firstInterval == 5, 1, 0),
Interval_6 = ifelse(firstInterval == 6, 1, 0),
Interval_7 = ifelse(firstInterval == 7, 1, 0),
Interval_8 = ifelse(firstInterval == 8, 1, 0),
Interval_9 = ifelse(firstInterval == 9, 1, 0),
Interval_10 = ifelse(firstInterval == 10, 1, 0),
Interval_11 = ifelse(firstInterval == 11, 1, 0),
Interval_12 = ifelse(firstInterval == 12, 1, 0),
Interval_13 = ifelse(firstInterval == 13, 1, 0),
Interval_14 = ifelse(firstInterval == 14, 1, 0),
Interval_15 = ifelse(firstInterval == 15, 1, 0),
Interval_16 = ifelse(firstInterval == 16, 1, 0),
Interval_17 = ifelse(firstInterval == 17, 1, 0),
Interval_18 = ifelse(firstInterval == 18, 1, 0),
Interval_19 = ifelse(firstInterval == 19, 1, 0),
Interval_20 = ifelse(firstInterval == 20, 1, 0),
Interval_21 = ifelse(firstInterval == 21, 1, 0),
Interval_22 = ifelse(firstInterval == 22, 1, 0),
Interval_23 = ifelse(firstInterval == 23, 1, 0),
Interval_24 = ifelse(firstInterval == 24, 1, 0))
### Change NA to zero for counts without detections
surveyData24 <-
surveyData24 %>%
mutate(Interval_1 = ifelse(is.na(firstInterval == TRUE), 0, Interval_1),
Interval_2 = ifelse(is.na(firstInterval == TRUE), 0, Interval_2),
Interval_3 = ifelse(is.na(firstInterval == TRUE), 0, Interval_3),
Interval_4 = ifelse(is.na(firstInterval == TRUE), 0, Interval_4),
Interval_5 = ifelse(is.na(firstInterval == TRUE), 0, Interval_5),
Interval_6 = ifelse(is.na(firstInterval == TRUE), 0, Interval_6),
Interval_7 = ifelse(is.na(firstInterval == TRUE), 0, Interval_7),
Interval_8 = ifelse(is.na(firstInterval == TRUE), 0, Interval_8),
Interval_9 = ifelse(is.na(firstInterval == TRUE), 0, Interval_9),
Interval_10 = ifelse(is.na(firstInterval == TRUE), 0, Interval_10),
Interval_11 = ifelse(is.na(firstInterval == TRUE), 0, Interval_11),
Interval_12 = ifelse(is.na(firstInterval == TRUE), 0, Interval_12),
Interval_13 = ifelse(is.na(firstInterval == TRUE), 0, Interval_13),
Interval_14 = ifelse(is.na(firstInterval == TRUE), 0, Interval_14),
Interval_15 = ifelse(is.na(firstInterval == TRUE), 0, Interval_15),
Interval_16 = ifelse(is.na(firstInterval == TRUE), 0, Interval_16),
Interval_17 = ifelse(is.na(firstInterval == TRUE), 0, Interval_17),
Interval_18 = ifelse(is.na(firstInterval == TRUE), 0, Interval_18),
Interval_19 = ifelse(is.na(firstInterval == TRUE), 0, Interval_19),
Interval_20 = ifelse(is.na(firstInterval == TRUE), 0, Interval_20),
Interval_21 = ifelse(is.na(firstInterval == TRUE), 0, Interval_21),
Interval_22 = ifelse(is.na(firstInterval == TRUE), 0, Interval_22),
Interval_23 = ifelse(is.na(firstInterval == TRUE), 0, Interval_23),
Interval_24 = ifelse(is.na(firstInterval == TRUE), 0, Interval_24))
surveyData25 <-
surveyData25 %>%
mutate(Interval_1 = ifelse(firstInterval == 1, 1, 0),
Interval_2 = ifelse(firstInterval == 2, 1, 0),
Interval_3 = ifelse(firstInterval == 3, 1, 0),
Interval_4 = ifelse(firstInterval == 4, 1, 0),
Interval_5 = ifelse(firstInterval == 5, 1, 0),
Interval_6 = ifelse(firstInterval == 6, 1, 0),
Interval_7 = ifelse(firstInterval == 7, 1, 0),
Interval_8 = ifelse(firstInterval == 8, 1, 0),
Interval_9 = ifelse(firstInterval == 9, 1, 0),
Interval_10 = ifelse(firstInterval == 10, 1, 0),
Interval_11 = ifelse(firstInterval == 11, 1, 0),
Interval_12 = ifelse(firstInterval == 12, 1, 0))
surveyData25 <-
surveyData25 %>%
mutate(Interval_1 = ifelse(is.na(firstInterval == TRUE), 0, Interval_1),
Interval_2 = ifelse(is.na(firstInterval == TRUE), 0, Interval_2),
Interval_3 = ifelse(is.na(firstInterval == TRUE), 0, Interval_3),
Interval_4 = ifelse(is.na(firstInterval == TRUE), 0, Interval_4),
Interval_5 = ifelse(is.na(firstInterval == TRUE), 0, Interval_5),
Interval_6 = ifelse(is.na(firstInterval == TRUE), 0, Interval_6),
Interval_7 = ifelse(is.na(firstInterval == TRUE), 0, Interval_7),
Interval_8 = ifelse(is.na(firstInterval == TRUE), 0, Interval_8),
Interval_9 = ifelse(is.na(firstInterval == TRUE), 0, Interval_9),
Interval_10 = ifelse(is.na(firstInterval == TRUE), 0, Interval_10),
Interval_11 = ifelse(is.na(firstInterval == TRUE), 0, Interval_11),
Interval_12 = ifelse(is.na(firstInterval == TRUE), 0, Interval_12))
## Sum counts per interval per point
surveyData23 <-
surveyData23 %>%
group_by(site,Count_Date,dayOfYear,Start_Time, surveyYear) %>%
summarise(Interval_1 = sum(Interval_1), # this model wants summed # of birds per Interval_
Interval_2 = sum(Interval_2),
Interval_3 = sum(Interval_3),
Interval_4 = sum(Interval_4))
surveyData24 <-
surveyData24 %>%
group_by(site,dayOfYear,Count_Date,Start_Time, surveyYear) %>%
summarise(Interval_1 = sum(Interval_1), # this model wants summed # of birds per Interval_
Interval_2 = sum(Interval_2), # and has to match the distance data
Interval_3 = sum(Interval_3),
Interval_4 = sum(Interval_4),
Interval_5 = sum(Interval_5),
Interval_6 = sum(Interval_6),
Interval_7 = sum(Interval_7),
Interval_8 = sum(Interval_8),
Interval_9 = sum(Interval_9),
Interval_10 = sum(Interval_10),
Interval_11 = sum(Interval_11),
Interval_12 = sum(Interval_12),
Interval_13 = sum(Interval_13),
Interval_14 = sum(Interval_14),
Interval_15 = sum(Interval_15),
Interval_16 = sum(Interval_16),
Interval_17 = sum(Interval_17),
Interval_18 = sum(Interval_18),
Interval_19 = sum(Interval_19),
Interval_20 = sum(Interval_20),
Interval_21 = sum(Interval_21),
Interval_22 = sum(Interval_22),
Interval_23 = sum(Interval_23),
Interval_24 = sum(Interval_24))
surveyData25 <-
surveyData25 %>%
group_by(site,Count_Date,dayOfYear,Start_Time, surveyYear) %>%
summarise(Interval_1 = sum(Interval_1), # this model wants summed # of birds per Interval_
Interval_2 = sum(Interval_2), # and has to match the distance data
Interval_3 = sum(Interval_3),
Interval_4 = sum(Interval_4),
Interval_5 = sum(Interval_5),
Interval_6 = sum(Interval_6),
Interval_7 = sum(Interval_7),
Interval_8 = sum(Interval_8),
Interval_9 = sum(Interval_9),
Interval_10 = sum(Interval_10),
Interval_11 = sum(Interval_11),
Interval_12 = sum(Interval_12))
#Combine all years
surveyDataAll <- bind_rows(surveyData23,surveyData24,surveyData25)
# calculate sunrise times at Corvallis Airport on each survey date.
sunriseTimes <- getSunlightTimes(date = surveyDataAll$Count_Date, lat = 44.50, lon = -123.28,
keep = c("sunrise"), tz="America/Los_Angeles")
#create a new variable in surveyData that has sunrise matched to the survey point.
#careful, here, because there is no matching function (i.e., this only works if the
#two data frames are sorted in the same order. This should be the case unless you
#sort one after calling this function).
surveyDataAll$sunrise <- sunriseTimes$sunrise
#subtract the two times to get decimal hours after sunrise.
surveyDataAll$mas <- 60*((surveyDataAll$Start_Time@hour + surveyDataAll$Start_Time@minute/60) -
(hour(surveyDataAll$sunrise) + minute(surveyDataAll$sunrise)/60))
#clean up
rm(sunriseTimes)
##Write file to CSV for easier import to reporting markdown:
write_csv(surveyDataAll, file = "/Users/johnlloyd/Documents/GitHub/hornedLarks/surveyDataAll.csv")
surveyData <- read.csv(file = "/Users/johnlloyd/Documents/GitHub/hornedLarks/surveyDataAll.csv",
header = TRUE,
sep = ",")
View(surveyDataAll)
yRemoval <- matrix(nrow = 822, ncol = 24)
rownames(yRemoval) <- surveyDataAll$site
yRemoval <- cbind(surveyDataAll[,6:29])
yRemoval <- as.matrix(yRemoval)
## Create the unmarked frame
umfR <- unmarkedFrameMPois(y = yRemoval, siteCovs = covs, obsToY = o2y, piFun = "remPi")
summary(umfR)
## initial distance-removal (DR) models.
Null <- multinomPois(~1 ~1, data = umfR)
summary(drNull)
p_test <- metrix(0.2, nrow = nrow(y), ncol = J)
p_test <- matrix(0.2, nrow = nrow(y), ncol = J)
## Factory that returns a piFun using a SITE-BY-INTERVAL times matrix
makeRemPiFun_bySite <- function(times_mat) {
stopifnot(is.matrix(times_mat))
function(p) {
# p is an M x J matrix of per-unit-time detection probabilities (0..1)
M <- nrow(p); J <- ncol(p)
if (!all(dim(times_mat) == c(M, J)))
stop("times_mat must have the same dimensions as p (sites x intervals).")
# Convert per-unit p to per-interval detection prob q = 1 - (1 - p)^t
q <- 1 - (1 - p)^times_mat
# No time => no chance to detect in that interval
q[is.na(times_mat) | times_mat <= 0] <- 0
# Survival (not yet detected) up to the start of interval j
surv <- matrix(1, M, J)
if (J > 1) for (j in 2:J) surv[, j] <- surv[, j - 1] * (1 - q[, j - 1])
# Multinomial cell probabilities: first detected in interval j
pi <- surv * q
# Return M x J matrix
pi
}
remPi <- makeRemPiFun(times_mat)
## Create the unmarked frame
umfR <- unmarkedFrameMPois(y = yRemoval, siteCovs = covs, obsToY = o2y, piFun = "remPi")
summary(umfR)
## initial distance-removal (DR) models.
Null <- multinomPois(~1 ~1, data = umfR)
## need obsToY in this case because we can't use the default removal model features due to unequal intervals
make_obsToY_removal <- function(J) {
stopifnot(J >= 1L)
o2y <- diag(J)
o2y[upper.tri(o2y)] <- 1L
o2y
}
J <- 24
o2y <- make_obsToY_removal(J)
dim(o2y)
View(times_mat)
remPi <- makeRemPiFun()
remPi <- makeRemPiFun_bySite()
remPi <- makeRemPiFun_bySite(times_mat)
## Create the unmarked frame
umfR <- unmarkedFrameMPois(y = yRemoval, siteCovs = covs, obsToY = o2y, piFun = "remPi")
summary(umfR)
## initial distance-removal (DR) models.
Null <- multinomPois(~1 ~1, data = umfR)
summary(Null)
# Detection probability after 1 removal interval
predict(Null, type = "det")
# Detection probability if counted for 12 intervals:
rowSums(getP(Null))[1]
# Detection probability if counted for 24 intervals:
rowSums(getP(Null))[550]
# Detection probability if counted for 24 intervals:
rowSums(getP(Null))[800]
View(Null)
summary(Null)
# Detection probability if counted for 24 intervals:
rowSums(getP(Null))[822]
# Detection probability if counted for 24 intervals:
rowSums(getP(Null))[823]
# Detection probability if counted for 24 intervals:
rowSums(getP(Null))[574]
# Detection probability if counted for 24 intervals:
rowSums(getP(Null))[575]
# Detection probability if counted for 24 intervals:
rowSums(getP(Null))[575,1:4]
(getP(Null))[575,1:4]
(getP(Null))[1,1:4]
View(Null)
getP(Null)
# Detection probability after 4 removal intervals
predict(Null, type = "det")
# Detection probability if counted for 24 intervals:
rowSums(getP(Null))[1,1:4]
P <- getP(Null)
p_start <- rowSums(P)
View(P)
rowSums(P[586,])
rowSums(P[586,1:24])
P[586,1:24]
rowSums(P[,1:24])
getP(Null)
rm(p_start)
p_star <- rowSums(P)
p_star
re <- ranef(Null)
Nhat <- bup(re, stat = "mean")
Nhat
hist(re[[1]])
hist(re[[575]])
hist(Nhat)
fit
fit(Null)
Year <- multinomPois(~Year ~1, data = umfR)
Year <- multinomPois(~surveyYear ~1, data = umfR)
Day <- multinomPois(~dayOfYear ~1, data = umfR)
Time <- multinomPois(~mas ~1, data = umfR)
Model_List <- fitList(Null = Null, Year = Year, Day = Day, Time = Time)
Model_Selection <- modSel(Model_List, nullmod = "Null")
Model_Selection
hist(yRemoval)
View(surveyData25)
View(surveyData23)
View(surveyData24)
Model_List_Detect <- fitList(Null = Null, Year = Year, Day = Day, Time = Time)
Model_Selection_Detect <- modSel(Model_List_Detect, nullmod = "Null")
Model_Selection_Detect #The null is only 1.49 AIC above best model (Time), so prefer null.
## initial removal models.
### Detectability
dNull <- multinomPois(~1 ~1, data = umfR)
dYear <- multinomPois(~surveyYear ~1, data = umfR)
dDay <- multinomPois(~dayOfYear ~1, data = umfR)
dTime <- multinomPois(~mas ~1, data = umfR)
Model_List_Detect <- fitList(Null = dNull, dYear = Year, dDay = Day, dTime = Time)
Model_Selection_Detect <- modSel(Model_List_Detect, nullmod = "Null")
Model_Selection_Detect #The null is only 1.49 AIC above best model (Time), so prefer null.
Model_Selection_Detect <- modSel(Model_List_Detect, nullmod = "dNull")
Model_List_Detect <- fitList(Null = dNull, Year = dYear, Day = dDay, Time = dTime)
Model_Selection_Detect <- modSel(Model_List_Detect, nullmod = "Null")
Model_Selection_Detect #The null is only 1.49 AIC above best model (Time), so prefer null.
### Abundance
aNull <- multinomPois(~1 ~1, data = umfR)
aYear <- multinomPois(~1 ~surveyYear, data = umfR)
Model_List_Abund <- fitList(Null = aNull, Year = aYear)
Model_Selection_Abund <-modSel(Model_List_Abund, nullmod = "Null")
summary(aYear)
summary(aNull)
log(-3.61/(1-(-3.61)))
backTransform(Null)
backTransform(Null, type = "det")
1-((0.0262)^24)
1-((0.0262)*24)
0.0262*24
1-0.6288
Model_Selection_Abund <-modSel(Model_List_Abund, nullmod = "Null")
Model_Selection_Abund
re <- ranef(Null)
bup(re, stat = "mean")
bup(re, stat = "mode")
sum(bup(re, stat = "mode"))
sum(bup(re))
View(re)
bup(re, stat = "mean")
#re <- ranef(Null) # ranef doesn't work in this case because of the NA for unsampled intervals in 2022, 2023, and 2025.
y_hat <- predict(Null, type= "det")
lambda_hat <- predict(Null, type = "state")
expected_count <- y_hat*lambda_hat
View(Year)
View(y_hat)
View(lambda_hat)
predict(Null, type = "det")
#re <- ranef(Null) # ranef doesn't work in this case because of the NA for unsampled intervals in 2022, 2023, and 2025.
Nmix.gof.test(Null)
#re <- ranef(Null) # ranef doesn't work in this case because of the NA for unsampled intervals in 2022, 2023, and 2025.
Nmix.gof.test(Null, nsim = 50)
#re <- ranef(Null) # ranef doesn't work in this case because of the NA for unsampled intervals in 2022, 2023, and 2025.
Nmix.gof.test(Null, nsim = 1000)
rm(re)
View(P)
rowSums(P)
rowSums(P[c(1,574,822),])
# Total detection probability for 2022/23 [1], 24[574], and 25[822]
print(rowSums(P[c(1,574,822),]))
rm(Nhat)
rm(p_star)
rm(y_hat)
getP(Null)
# Total detection probability for 2022/23 [1], 24[574], and 25[822]
P <- getP(Null)
print(rowSums(P[c(1,574,822),]))
#
predict(Null, type = "state")
beta <- coef(Null, type = "state")
X <- getData(Null)@X
View(Null)
X <- getData(Null)$X
getDesign(Null)
X <- getData(Null)
lambda_hat <- exp(X %*% beta)
rm(beta)
rm(X)
rm(lambda_hat)
fitted(Null)
fitted(Null)[574,]
sum(fitted(Null)[574,])
sum(fitted(Null)[575,])
sum(fitted(Null)[822,])
sum(fitted(Null)[1,])
confint(Null, type = "state", method = "profile")
confint(Null, type = "state")
backTransform(Null, type = "state")
