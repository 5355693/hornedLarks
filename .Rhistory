surveyData24$Interval_20 <- factor(surveyData24$Interval_20, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData24$Interval_21 <- factor(surveyData24$Interval_21, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData24$Interval_22 <- factor(surveyData24$Interval_22, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData24$Interval_23 <- factor(surveyData24$Interval_23, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData24$Interval_24 <- factor(surveyData24$Interval_24, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
## Add a "first detected by..." column to survey data:
surveyData24 <-
surveyData24 %>%
pivot_longer(., cols = 7:30, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(detection)) %>%
right_join(., surveyData24, by = 'Lark_ID', keep = F)
## Add a "first interval detected..." column to survey data:
surveyData24 <-
surveyData24 %>%
pivot_longer(., cols = 8:31, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(interval)) %>%
mutate(firstInterval = ifelse(firstDet == "Interval_1",1,
ifelse(firstDet == "Interval_2", 2,
ifelse(firstDet == "Interval_3", 3,
ifelse(firstDet == "Interval_4", 4,
ifelse(firstDet == "Interval_5", 5,
ifelse(firstDet == "Interval_6", 6,
ifelse(firstDet == "Interval_7", 7,
ifelse(firstDet == "Interval_8", 8,
ifelse(firstDet == "Interval_9", 9,
ifelse(firstDet == "Interval_10", 10,
ifelse(firstDet == "Interval_11", 11,
ifelse(firstDet == "Interval_12", 12,
ifelse(firstDet == "Interval_13", 13,
ifelse(firstDet == "Interval_14", 14,
ifelse(firstDet == "Interval_15", 15,
ifelse(firstDet == "Interval_16", 16,
ifelse(firstDet == "Interval_17", 17,
ifelse(firstDet == "Interval_18", 18,
ifelse(firstDet == "Interval_19", 19,
ifelse(firstDet == "Interval_20", 20,
ifelse(firstDet == "Interval_21", 21,
ifelse(firstDet == "Interval_22", 22,
ifelse(firstDet == "Interval_23", 23,
ifelse(firstDet == "Interval_24", 24,NA)))))))))))))))))))))))))%>%
right_join(., surveyData24, by = 'Lark_ID', keep = F) %>%
select(!(firstDet.x)) %>%
rename(firstDet = firstDet.y)
#2025
## This file reads in with ~1000 extra rows, all blank, unless n_max is specified
surveyData25 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv",n_max = 159)
surveyData25 <-
surveyData25 %>%
select(unique_ID, Survey_Date,Survey_Time,Lark_ID, Min_1,Min_2,Min_3,Min_4,Min_5,Min_6,
Min_7,Min_8,Min_9,Min_10,Min_11,Min_12) %>%
mutate(site = factor(unique_ID),
Lark_ID = factor(Lark_ID)) %>%
select(-unique_ID)
surveyData25$Count_Date <- mdy(surveyData25$Survey_Date)
surveyData25$Start_Time <- hms(surveyData25$Survey_Time)
surveyData25$dayOfYear <- yday(surveyData25$Count_Date) # create a day-of-year variable for analysis
surveyData25$surveyYear <- year(surveyData25$Count_Date)
surveyData25 <-
surveyData25 %>%
select(-Survey_Date, -Survey_Time)
surveyData25$Interval_1 <- ifelse(surveyData25$Min_1 == "X", NA, surveyData25$Min_1)
surveyData25$Interval_2 <- ifelse(surveyData25$Min_2 == "X", NA, surveyData25$Min_2)
surveyData25$Interval_3 <- ifelse(surveyData25$Min_3 == "X", NA, surveyData25$Min_3)
surveyData25$Interval_4 <- ifelse(surveyData25$Min_4 == "X", NA, surveyData25$Min_4)
surveyData25$Interval_5 <- ifelse(surveyData25$Min_5 == "X", NA, surveyData25$Min_5)
surveyData25$Interval_6 <- ifelse(surveyData25$Min_6 == "X", NA, surveyData25$Min_6)
surveyData25$Interval_7 <- ifelse(surveyData25$Min_7 == "X", NA, surveyData25$Min_7)
surveyData25$Interval_8 <- ifelse(surveyData25$Min_8 == "X", NA, surveyData25$Min_8)
surveyData25$Interval_9 <- ifelse(surveyData25$Min_9 == "X", NA, surveyData25$Min_9)
surveyData25$Interval_10 <- ifelse(surveyData25$Min_10 == "X", NA, surveyData25$Min_10)
surveyData25$Interval_11 <- ifelse(surveyData25$Min_11 == "X", NA, surveyData25$Min_11)
surveyData25$Interval_12 <- ifelse(surveyData25$Min_12 == "X", NA, surveyData25$Min_12)
surveyData25 <-
surveyData25 %>%
select(-Min_1,-Min_2,-Min_3, -Min_4,-Min_5,
-Min_6,-Min_7,-Min_8, -Min_9, -Min_10,
-Min_11, -Min_12)
surveyData25$Interval_1 <- factor(surveyData25$Interval_1, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_2 <- factor(surveyData25$Interval_2, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_3 <- factor(surveyData25$Interval_3, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_4 <- factor(surveyData25$Interval_4, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_5 <- factor(surveyData25$Interval_5, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_6 <- factor(surveyData25$Interval_6, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_7 <- factor(surveyData25$Interval_7, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_8 <- factor(surveyData25$Interval_8, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_9 <- factor(surveyData25$Interval_9, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_10 <- factor(surveyData25$Interval_10, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_11 <- factor(surveyData25$Interval_11, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData25$Interval_12 <- factor(surveyData25$Interval_12, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
## Add a "first detected by..." column to survey data:
surveyData25 <-
surveyData25 %>%
pivot_longer(., cols = 7:18, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(detection)) %>%
right_join(., surveyData25, by = 'Lark_ID', keep = F)
## Add a "first interval detected..." column to survey data:
surveyData25 <-
surveyData25 %>%
pivot_longer(., cols = 8:19, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(interval)) %>%
mutate(firstInterval = ifelse(firstDet == "Interval_1",1,
ifelse(firstDet == "Interval_2", 2,
ifelse(firstDet == "Interval_3", 3,
ifelse(firstDet == "Interval_4", 4,
ifelse(firstDet == "Interval_5", 5,
ifelse(firstDet == "Interval_6", 6,
ifelse(firstDet == "Interval_7", 7,
ifelse(firstDet == "Interval_8", 8,
ifelse(firstDet == "Interval_9", 9,
ifelse(firstDet == "Interval_10", 10,
ifelse(firstDet == "Interval_11", 11,
ifelse(firstDet == "Interval_12", 12,NA)))))))))))))%>%
right_join(., surveyData25, by = 'Lark_ID', keep = F) %>%
select(!(firstDet.x)) %>%
rename(firstDet = firstDet.y)
View(surveyData23)
intervals <- rbind(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval)
View(intervals)
intervals <- cbind(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval)
View(intervals)
intervals <- cbind(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval) %>%
pivot_longer(., 1:2, names_to = "Interval", values_to "Time")
intervals <- cbind(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval) %>%
pivot_longer(., 1:2, names_to = "Interval", values_to = "Time")
intervals <-
cbind(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval) %>%
pivot_longer(., 1:2, names_to = "Interval", values_to = "Time")
intervals <-
as.data.frame(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval) %>%
pivot_longer(., 1:2, names_to = "Interval", values_to = "Time")
intervals <-
as.data.frame(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval)
intervals <- c(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval) %>%
pivot_longer(., 1:2, names_to = "Interval", values_to = "Time")
intervals <- c(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval)
intervals
ggplot(intervals) + geom_histogram()
intervals <- data.frame(c(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval))
View(intervals)
intervals <- data.frame(c(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval))%>%
colnames[1]<-'interval'
intervals <- data.frame(c(surveyData23$firstInterval, surveyData24$firstInterval, surveyData25$firstInterval))%>%
colnames(intervals) <- "Interval"
ggplot(intervals, aes(x = Interval)) + geom_histogram()
ggplot(intervals, aes(x = Interval)) + geom_histogram(binwidth = 1)
ggplot(intervals, aes(x = Interval)) + geom_histogram(binwidth = 1) +
ylab("No. of detections") + xlab("Interval") +
theme(axis.title = element_text(size = 18),
axis.text = element_text(size = 14))
write.csv(surveyData23, file = "~/Documents/GitHub/hornedLarks/all_data_2023.csv")
write.csv(surveyData24, file = "~/Documents/GitHub/hornedLarks/all_data_2024.csv")
write.csv(surveyData25, file = "~/Documents/GitHub/hornedLarks/all_data_2025.csv")
#| label: Detection intervals.
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Frequency of lark detections by time interval during a survey."
#| fig-width: 12
#| fig-height: 4
all_data_23 <- read.csv("~/Documents/GitHub/hornedLarks/all_data_2025.csv")
all_data_24 <- read.csv("~/Documents/GitHub/hornedLarks/all_data_2025.csv")
all_data_25 <- read.csv("~/Documents/GitHub/hornedLarks/all_data_2025.csv")
intervals <- data.frame(c(all_data_23$firstInterval, all_data_24$firstInterval, all_data_25$firstInterval))
colnames(intervals) <- "Interval"
ggplot(intervals, aes(x = Interval)) + geom_histogram(binwidth=1) +
ylab("No. of detections") + xlab("Interval") +
theme(axis.title = element_text(size = 18),
axis.text = element_text(size = 14))
ggplot(intervals, aes(x = Interval)) + geom_histogram(binwidth = 1) +
ylab("No. of detections") + xlab("Interval") +
theme(axis.title = element_text(size = 18),
axis.text = element_text(size = 14))
View(intervals)
## Detection and abundance.
surveyData <- read.csv(file = "/Users/johnlloyd/Documents/GitHub/hornedLarks/surveyDataAll.csv",
header = TRUE,
sep = ",")
times_mat <- matrix(NA,822,24)
times_mat[1:573,1:4] <- 2
times_mat[1:573,5:24] <- 0
times_mat[574:682,1:24] <- 1
times_mat[683:822,1:12] <- 1
times_mat[683:822,13:24] <- 0
## Factory that returns a piFun using a SITE-BY-INTERVAL times matrix
makeRemPiFun_bySite <- function(times_mat) {
stopifnot(is.matrix(times_mat))
function(p) {
# p is an M x J matrix of per-unit-time detection probabilities (0..1)
M <- nrow(p); J <- ncol(p)
if (!all(dim(times_mat) == c(M, J)))
stop("times_mat must have the same dimensions as p (sites x intervals).")
# Convert per-unit p to per-interval detection prob q = 1 - (1 - p)^t
q <- 1 - (1 - p)^times_mat
# No time => no chance to detect in that interval
q[is.na(times_mat) | times_mat <= 0] <- 0
# Survival (not yet detected) up to the start of interval j
surv <- matrix(1, M, J)
if (J > 1) for (j in 2:J) surv[, j] <- surv[, j - 1] * (1 - q[, j - 1])
# Multinomial cell probabilities: first detected in interval j
pi <- surv * q
# Return M x J matrix
pi
}
remPi <- makeRemPiFun_bySite(times_mat)
## need obsToY in this case because we can't use the default removal model features due to unequal intervals
make_obsToY_removal <- function(J) {
stopifnot(J >= 1L)
o2y <- diag(J)
o2y[upper.tri(o2y)] <- 1L
o2y
}
J <- 24
o2y <- make_obsToY_removal(J)
dim(o2y)
yRemoval <- matrix(nrow = 822, ncol = 24)
rownames(yRemoval) <- surveyDataAll$site
yRemoval <- cbind(surveyDataAll[,6:29])
View(surveyData)
rownames(yRemoval) <- surveyData$site
yRemoval <- cbind(surveyData[,6:29])
yRemoval <- as.matrix(yRemoval)
## Create a data frame of site-level covariates.
covs <-
surveyDataAll %>%
group_by(site, surveyYear, dayOfYear) %>%
summarise(site = first(site),
dayOfYear = first (dayOfYear),
mas = first(mas))
library(tidyverse)
library(readxl)
library(lubridate)
library(suncalc)
library(ggpmisc)
library(unmarked)
library(AICcmodavg)
library(ubms)
library(knitr)
library(kableExtra)
library(ggpmisc)
library(ubms)
library(gt)
## Create a data frame of site-level covariates.
covs <-
surveyDataAll %>%
group_by(site, surveyYear, dayOfYear) %>%
summarise(site = first(site),
dayOfYear = first (dayOfYear),
mas = first(mas))
## Create a data frame of site-level covariates.
covs <-
surveyData %>%
group_by(site, surveyYear, dayOfYear) %>%
summarise(site = first(site),
dayOfYear = first (dayOfYear),
mas = first(mas))
## Create the unmarked frame
umfR <- unmarkedFrameMPois(y = yRemoval, siteCovs = covs, obsToY = o2y, piFun = "remPi")
summary(umfR)
## initial removal models.
### Detectability
dNull <- multinomPois(~1 ~1, data = umfR)
dYear <- multinomPois(~surveyYear ~1, data = umfR)
dDay <- multinomPois(~dayOfYear ~1, data = umfR)
dTime <- multinomPois(~mas ~1, data = umfR)
Model_List_Detect <- fitList(Null = dNull, Year = dYear, Day = dDay, Time = dTime)
Model_Selection_Detect <- modSel(Model_List_Detect, nullmod = "Null")
Model_Selection_Detect #The null is only 1.49 AIC above best model (Time), so prefer null.
#colnames(Model_Selection_Detect)[1] <- "Year"
#colnames(Model_Selection_Detect)[2] <- "No. of larks detected on a survey"
#colnames(Model_Selection_Detect)[3] <- "No. surveys"
Model_Selection_Detect %>%
gt() %>%
tab_header(
title = "Lark encounters per year"
)
Model_Selection_Detect.df <- as.data.frame(Model_Selection_Detect)
Model_Selection_Detect@Full$model
Model_Selection_Detect.df$Model <- as.data.frame(Model_Selection_Detect@Full$model)
Model_Selection_Detect.df <- as.data.frame(Model_Selection_Detect@Full$model)
View(Model_Selection_Detect.df)
Model_Selection_Detect.df$AIC <- Model_Selection_Detect@Full$AIC
Model_Selection_Detect.df$Weight <- Model_Selection_Detect@Full$AICwt
colnames(Model_Selection_Detect.df)[1] <- "Model"
colnames(Model_Selection_Detect.df)[2] <- "AIC"
colnames(Model_Selection_Detect.df)[3] <- "Model weight"
Model_Selection_Detect.df %>%
gt() %>%
tab_header(
title = "Detectability models ranked."
)
Model_Selection_Detect.df %>%
gt() %>%
tab_header(
title = "Detectability models ranked."
) %>%
fmt_number(
columns = AIC, `Model weight`,
decimals = 2
)
Model_Selection_Detect.df %>%
gt() %>%
tab_header(
title = "Detectability models ranked."
) %>%
fmt_number(
columns = `Model weight`,
decimals = 2
)
Model_Selection_Detect.df %>%
gt() %>%
tab_header(
title = "Detectability models ranked."
) %>%
fmt_number(
columns = `Model weight`,
decimals = 2
) %>%
fmt_number(
columns = AIC,
decimals = 0
)
# Total detection probability for 2022/23 [1], 24[574], and 25[822]
P <- getP(Null)
# Total detection probability for 2022/23 [1], 24[574], and 25[822]
P <- getP(dNull)
P
print(rowSums(P[c(1,574,822),]))
# Total detection probability for 2022/23 [1], 24[574], and 25[822]
P <- getP(dNull)[574]
P
# Total detection probability for 2022/23 [1], 24[574], and 25[822]
P <- getP(dNull)[574,]
P
# Total detection probability for 2022/23 [1], 24[574], and 25[822]
P <- getP(dNull)[822,]
P
# Total detection probability for 2022/23 [1], 24[574], and 25[822]
P <- getP(dNull)[574,]
P
getP(dNull)[574,] %>%
summary(dNull)
getP(dNull)[574,] %>%
coef(summary(dNull))
drNull@estimates$det
dNull@estimates$det
dNull@estimates$det@estimates
summary(dNull)$coefficents
coef_table <- summary(dNull)$coefficients
coef_table <- summary(dNull)
View(coef_table)
coef_table$det$SE
predict(dNull, type = "det", se.fit = TRUE)
1-0.2621512
1-0.02621512
0.02621512*(1-0.02621512)
coef_table<- summary(dNull)
detect_rows <- grep("^p", rownames(coef_table))
detect_se <- coef_table[detect_rows, "SE"]
View(covs)
View(coef_table)
coef_table<- summary(dNull@estimates@estimates$det)
P
p_matrix <- getP(dNull)
p_cumulative <- 1 - apply(1-p_matrix,1, prod)
rm(p_matrix)
rm(p_cumulative)
beta_det <- coef(dNull, type = "det")
vcov_det <- vcov(dNull)[1:length(beta_det), 1:length(beta_det)]
detect_fun <-function (k) {
paste0("( (1-plogis(x1))^", k - 1, " ) * plogis(x1)")
}
intervals <- 1:24
estimates <- numeric(length(intervals))
ses <- numeric(length(intervals))
for (k in intervals) {
expr <- detect_fun(k)
estimates[k] <- eval(parse(text = gsub("x1", beta_det[1], expr)))
ses[k] <- deltamethod(as.formula(paste("~", expr)), mean = beta_det, cov = vcov_det)
}
install.packages("msm")
library(msm)
for (k in intervals) {
expr <- detect_fun(k)
estimates[k] <- eval(parse(text = gsub("x1", beta_det[1], expr)))
ses[k] <- deltamethod(as.formula(paste("~", expr)), mean = beta_det, cov = vcov_det)
}
for (k in intervals) {
expr <- detect_fun(k)
p_val <- 1/(1+ exp(-beta_det[1]))
estimates[k] <- e(1- p_val)^(k-1) * p_val
ses[k] <- deltamethod(as.formula(paste("~", expr)), mean = beta_det, cov = vcov_det)
}
for (k in intervals) {
expr <- detect_fun(k)
p_val <- 1/(1+ exp(-beta_det[1]))
estimates[k] <- (1- p_val)^(k-1) * p_val
ses[k] <- deltamethod(as.formula(paste("~", expr)), mean = beta_det, cov = vcov_det)
}
predict(dNull, type = "det")
getP(dNull)[574,]
getP(dNull)[574,] %>%
mutate(com_sum = cumsum())
ps <- data.frame(getP(dNull)[574,])
ps %>%
mutate(com_sum = cumsum[,1])
colnames(ps) <- P
View(ps)
colnames(ps) <- "P"
ps %>%
mutate(com_sum = cumsum(P))
rownames(ps)
ps %>%
mutate(com_sum = cumsum(P)) %>%
mutate(Interval = rownames(P))
ps %>%
mutate(Probability of detection = cumsum(P)) %>%
ps %>%
mutate('Probability of detection' = cumsum(P)) %>%
mutate(Interval = rownames(P))
ps %>%
mutate('Probability of detection' = cumsum(P)) %>%
mutate(Interval == rownames(P))
ps %>%
mutate('Probability of detection' = cumsum(P)) %>%
ps$Interval <- rownames(P)
ps %>%
mutate('Probability of detection' = cumsum(P)) %>%
mutate(Interval = rownames()
ps %>%
mutate('Probability of detection' = cumsum(P)) %>%
mutate(Interval = rownames())
ps %>%
mutate('Probability of detection' = cumsum(P)) %>%
mutate(Interval = rownames(P))
View(ps)
ps <-
ps %>%
mutate('Probability of detection' = cumsum(P)) %>%
mutate(Interval = rownames(P))
ps$Interval <- rownames(P)
ps$Interval <- seq(1:24,1)
ps$Interval <- seq(1,24,1)
ps %>%
ggplot(., aes(x = Interval, y = 'Probability of detection')) + geom_line()
ps %>%
ggplot(., aes(x = Interval, y = Probability of detection)) + geom_line()
ps <-
ps %>%
mutate(detection_rate = cumsum(P))
ps$Interval <- seq(1,24,1)
ps %>%
ggplot(., aes(x = Interval, y = detection_rate)) + geom_line()
ps %>%
ggplot(., aes(x = Interval, y = detection_rate)) + geom_line() +
labs(x = "Interval (minute)", y = "Cumulative probability of detection")
ps %>%
ggplot(., aes(x = Interval, y = detection_rate)) + geom_line() +
labs(x = "Interval (minute)", y = "Cumulative probability of detection") +
theme(axis.title = element_text(size = 18),
axis.text = element_text(size = 14))
confint(dNull, type = "det")
predict(dNull, type =
"det")
)
predict(dNull, type = "det")[1,]
predict(dNull, type = "det")[1,1]
round(predict(dNull, type = "det")[1,1], 2)
round(predict(dNull, type = "det")[1,1], 3)
rowSums(P)[554,]
P
sum(P)
ps %>%
ggplot(., aes(x = Interval, y = detection_rate)) + geom_line() +
labs(x = "Interval (minute)", y = "Cumulative probability\nof detection") +
theme(axis.title = element_text(size = 18),
axis.text = element_text(size = 14))
aNull <- multinomPois(~1 ~1, data = umfR)
aYear <- multinomPois(~1 ~surveyYear, data = umfR)
Model_List_Abund <- fitList(Null = aNull, Year = aYear)
Model_Selection_Abund <-modSel(Model_List_Abund, nullmod = "Null")
Model_Selection_Abund #Null preferred
predict(aNull, type = "state")
304*2*pi
304^2*pi
1.64/29
1.64/0.29
View(surveyData)
