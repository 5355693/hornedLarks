umf <- unmarkedFrameDS(y = as.matrix(yDat), siteCovs = as.data.frame(covs),
survey = "point", dist.breaks = c(0,25,100,200,400), unitsIn = "m")
getwd()
setwd("/Users/johnlloyd/Documents/GitHub/hornedLarks")
getwd()
dists <-
surveyData %>%
group_by(Site_ID) %>%
mutate(distance = ifelse(distanceBand == 1, 12.5,
ifelse(distanceBand == 2, 61,
ifelse(distanceBand == 3, 150,
ifelse(distanceBand == 4, 300, NA))))) %>%
select(Site_ID, distance, Sex, firstDet) %>%
filter(!is.na(distance), firstDet == "Singing", Sex == "Male")
## Note here that we need the "as.data.frame" argument because 'dists' is a tidyverse tibble,
## and unmarked doesn't seem to like tibbles. This forces it into a standard R data frame.
yDat <- formatDistData(distData = as.data.frame(dists), distCol = "distance", transectNameCol = "Site_ID",
dist.breaks = c(0,25,100,200,400))
## Create a data frame of site-level covariates.
covs <-
surveyData %>%
group_by(Site_ID) %>%
summarise(site = first(Site_ID),
observer = first(Observer),
temp = first(Temp),
avgNoise = first(Avg_Noise),
dayOfYear = first (dayOfYear),
mas = first(mas))
umf <- unmarkedFrameDS(y = as.matrix(yDat), siteCovs = as.data.frame(covs),
survey = "point", dist.breaks = c(0,25,100,200,400), unitsIn = "m")
summary(umf)
hist(umf, freq = TRUE, xlab = "Distance (m)", main = "Streaked Horned Lark detections 2022", cex.lab = 0.8, cex.axis = 0.8)
hnNull <- distsamp(~1~1, umf, keyfun = "halfnorm", output = "density", unitsOut = "kmsq")
hnNull
backTransform(hnNull, type = "state")
backTransform(hnNull, type = "det")
# calculating detection probability
sig <- exp(coef(hnNull, type="det"))
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
sqrt(ea / pi) # effective radius
# detection probability
ea / (pi*400^2)
#Half-normal, MAS
hnMAS <- distsamp(~mas ~1, umf, keyfun = "halfnorm", output = "density", unitsOut = "kmsq")
hnMAS
#Back-transformed detection probability for the average MAS
sig <- backTransform(linearComb(hnMAS['det'], c(1, mean(covs$mas))))@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
sqrt(ea / pi) # effective radius
# detection probability
ea / (pi*400^2)
# Half-normal, Day of year
hnDay <- distsamp(~dayOfYear ~1, data = umf, keyfun = "halfnorm", output = "density", unitsOut = "kmsq")
hnDay
#Back-transformed detection probability for the average day of year
sig <- backTransform(linearComb(hnDay['det'], c(1, mean(covs$dayOfYear))))@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
sqrt(ea / pi) # effective radius
# detection probability
ea / (pi*400^2)
# Half-normal, noise
hnNoise <- distsamp(~avgNoise ~1, data = umf, keyfun = "halfnorm", output = "density", unitsOut = "kmsq")
hnNoise
#Back-transformed detection probability for the average day of year
sig <- backTransform(linearComb(hnNoise['det'], c(1, mean(covs$avgNoise))))@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
sqrt(ea / pi) # effective radius
# detection probability
ea / (pi*400^2)
# Half-normal, Temp
hnTemp <- distsamp(~temp ~1, data = umf, keyfun = "halfnorm", output = "density", unitsOut = "kmsq")
hnTemp
#Back-transformed detection probability for the average day of year
sig <- backTransform(linearComb(hnTemp['det'], c(1, mean(covs$temp))))@estimate
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
sqrt(ea / pi) # effective radius
# detection probability
ea / (pi*400^2)
# Hazard-rate models
haNull <- distsamp(~1 ~1, data = umf, keyfun = "hazard", output = "density", unitsOut = "kmsq")
haNoise <- distsamp(~avgNoise ~1, data = umf, keyfun = "hazard", output = "density", unitsOut = "kmsq")
haTemp <- distsamp(~temp ~1, data = umf, keyfun = "hazard", output = "density", unitsOut = "kmsq")
haDay <- distsamp(~dayOfYear ~1, data = umf, keyfun = "hazard", output = "density", unitsOut = "kmsq")
haMAS <- distsamp(~mas ~1, data = umf, keyfun = "hazard", output = "density", unitsOut = "kmsq")
fmList <- list("haNull" = haNull, "haDay" = haDay, "haNoise" = haNoise, "haMAS" = haMAS, "haTemp" = haTemp,
"hnNull" = hnNull, "hnDay" = hnDay, "hnNoise" = hnNoise, "hnMAS" = hnMAS, "hnTemp" = hnTemp)
tableDistanceAIC <- aictab(cand.set = fmList, second.ord = T, sort = T)
View(tableDistanceAIC)
backTransform(hnNull, type = "det")
sig <- exp(coef(hnNull, type="det"))
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
sqrt(ea / pi) # effective radius
# detection probability
ea / (pi*400^2)
fitstats <- function(hnNull) {
observed <- getY(hnNull@data)
expected <- fitted(hnNull)
resids <- residuals(hnNull)
sse <- sum(resids^2)
chisq <- sum((observed - expected)^2 / expected)
freeTuke <- sum((sqrt(observed) - sqrt(expected))^2)
out <- c(SSE=sse, Chisq=chisq, freemanTukey=freeTuke)
return(out)
}
(pb <- parboot(hnNull, fitstats, nsim=25, report=1))
getP <- function(hnNull) {
sig <- exp(coef(hnNull, type="det"))
ea <- 2*pi * integrate(grhn, 0, 400, sigma=sig)$value # effective area
er <- sqrt(ea / pi) # effective radius
p <- ea / (pi*400^2) # detection probability
out <- c(p = p, er = er)
return(out)
}
parboot(hnNull, getP, nsim = 25, report = 1)
## Estimating density with a parametric bootstrap
getD <- function(hnNull) {
d <- backTransform(hnNull, type = "state")@estimate
return(d)
}
parboot(hnDay, getD, nsim = 25, report = 1)
backTransform(hnNull, type = "state")
getwd()
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
library(tidyverse)
library(readxl)
library(lubridate)
library(suncalc)
library(ggpmisc)
library(unmarked)
library(AICcmodavg)
library(ubms)
library(knitr)
library(kableExtra)
library(ggpmisc)
library(ubms)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
View(surveyData)
names(surveyData)[5] <- 'surveyEvent'
surveyData$surveyEvent <- factor(surveyData$surveyEvent)
#surveyData$Count_Date <- mdy(surveyData$Count_Date)
surveyData$Count_Date <- mdy(surveyData$Survey_Date)
#surveyData$Start_Time <- hms(surveyData$Start_Time)
surveyData$Start_Time <- hms(surveyData$Survey_Time)
surveyData$Site_ID <- factor(surveyData$unique_ID)
surveyData$Observer <- factor(surveyData$Observer)
surveyData$Sky_Code <- factor(surveyData$Sky_Code, levels = c("0","1","2","3","4"),
labels = c("Clear","Partly cloudy","Mostly cloudy","Fog or smoke","Drizzle"))
surveyData$Sex <- factor(surveyData$Sex, levels = c("M","F","U"), labels = c("Male","Female","Unknown"))
surveyData$Age <- factor(surveyData$Age, levels = c("A", "J"), labels = c("Adult", "Juvenile"))
surveyData$Interval_1 <- ifelse(surveyData$Min_1 == "X", NA, surveyData$Min_1)
surveyData$Interval_2 <- ifelse(surveyData$Min_2 == "X", NA, surveyData$Min_2)
surveyData$Interval_3 <- ifelse(surveyData$Min_3 == "X", NA, surveyData$Min_3)
surveyData$Interval_4 <- ifelse(surveyData$Min_4 == "X", NA, surveyData$Min_4)
surveyData$Interval_5 <- ifelse(surveyData$Min_5 == "X", NA, surveyData$Min_5)
surveyData$Interval_6 <- ifelse(surveyData$Min_6 == "X", NA, surveyData$Min_6)
surveyData$Interval_7 <- ifelse(surveyData$Min_7 == "X", NA, surveyData$Min_7)
surveyData$Interval_8 <- ifelse(surveyData$Min_8 == "X", NA, surveyData$Min_8)
surveyData$Interval_9 <- ifelse(surveyData$Min_9 == "X", NA, surveyData$Min_9)
surveyData$Interval_10 <- ifelse(surveyData$Min_10 == "X", NA, surveyData$Min_10)
surveyData$Interval_11 <- ifelse(surveyData$Min_11 == "X", NA, surveyData$Min_11)
surveyData$Interval_12 <- ifelse(surveyData$Min_12 == "X", NA, surveyData$Min_12)
surveyData$Interval_13 <- ifelse(surveyData$Min_13 == "X", NA, surveyData$Min_13)
surveyData$Interval_14 <- ifelse(surveyData$Min_14 == "X", NA, surveyData$Min_14)
surveyData$Interval_15 <- ifelse(surveyData$Min_15 == "X", NA, surveyData$Min_15)
surveyData$Interval_16 <- ifelse(surveyData$Min_16 == "X", NA, surveyData$Min_16)
surveyData$Interval_17 <- ifelse(surveyData$Min_17 == "X", NA, surveyData$Min_17)
surveyData$Interval_18 <- ifelse(surveyData$Min_18 == "X", NA, surveyData$Min_18)
surveyData$Interval_19 <- ifelse(surveyData$Min_19 == "X", NA, surveyData$Min_19)
surveyData$Interval_20 <- ifelse(surveyData$Min_20 == "X", NA, surveyData$Min_20)
surveyData$Interval_21 <- ifelse(surveyData$Min_21 == "X", NA, surveyData$Min_21)
surveyData$Interval_22 <- ifelse(surveyData$Min_22 == "X", NA, surveyData$Min_22)
surveyData$Interval_23 <- ifelse(surveyData$Min_23 == "X", NA, surveyData$Min_23)
surveyData$Interval_24 <- ifelse(surveyData$Min_24 == "X", NA, surveyData$Min_24)
surveyData$Interval_25 <- ifelse(surveyData$Min_25 == "X", NA, surveyData$Min_25)
surveyData$Interval_26 <- ifelse(surveyData$Min_26 == "X", NA, surveyData$Min_26)
surveyData$Interval_27 <- ifelse(surveyData$Min_27 == "X", NA, surveyData$Min_27)
surveyData$Interval_28 <- ifelse(surveyData$Min_28 == "X", NA, surveyData$Min_28)
surveyData$Interval_29 <- ifelse(surveyData$Min_29 == "X", NA, surveyData$Min_29)
surveyData$Interval_30 <- ifelse(surveyData$Min_30 == "X", NA, surveyData$Min_30)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
View(surveyData)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
View(surveyData)
surveyData <-
surveyData %>%
select(-Interval_1,Interval_2)
surveyData <-
surveyData %>%
select(-Interval_1,-Interval_2)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
surveyData <-
surveyData %>%
select(-Interval_1,-Interval_2)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
surveyData <-
surveyData %>%
select(-OffRoad_ID, -OffRoad,
-Distance_Band, -Wind,
-Avg_Noise, -Max_Noise,
-Interval_1,-Interval_2, -Interval_3, -Interval_4)
View(surveyData)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
surveyData <-
surveyData %>%
select(-OffRoad_ID, -OffRoad,
-Distance_Band, -Wind,
-Avg_Noise, -Max_Noise,
-Interval_1,-Interval_2, -Interval_3, -Interval_4,
-Distance_2,-Min_13,-Min_14,-Min_15,-Min_16,
-Distance_3,-Min_17,-Min_18,-Min_19,-Min_20,
-Min_21,-Min_22,-Min_23,-Min_24,-Min_25,
-Min_26,-Min_27,-Min_28,-Min_29,-Min_30,-PB_Distance_4,
-PB_Distance_5)
View(surveyData)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
#surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
surveyData <-
surveyData %>%
select(-OffRoad_ID, -OffRoad,
-Distance_Band, -Wind,
-Avg_Noise, -Max_Noise,
-Interval_1,-Interval_2, -Interval_3, -Interval_4,
-Distance_2,-Min_13,-Min_14,-Min_15,-Min_16,
-Distance_3,-Min_17,-Min_18,-Min_19,-Min_20,
-Min_21,-Min_22,-Min_23,-Min_24,-Min_25,
-Min_26,-Min_27,-Min_28,-Min_29,-Min_30,-PB_Distance_4,
-PB_Distance_5,-`OVSP?`)
names(surveyData)[5] <- 'surveyEvent'
surveyData$surveyEvent <- factor(surveyData$surveyEvent)
#surveyData$Count_Date <- mdy(surveyData$Count_Date)
surveyData$Count_Date <- mdy(surveyData$Survey_Date)
#surveyData$Start_Time <- hms(surveyData$Start_Time)
surveyData$Start_Time <- hms(surveyData$Survey_Time)
surveyData$Site_ID <- factor(surveyData$unique_ID)
surveyData$Observer <- factor(surveyData$Observer)
surveyData$Sky_Code <- factor(surveyData$Sky_Code, levels = c("0","1","2","3","4"),
labels = c("Clear","Partly cloudy","Mostly cloudy","Fog or smoke","Drizzle"))
surveyData$Sex <- factor(surveyData$Sex, levels = c("M","F","U"), labels = c("Male","Female","Unknown"))
surveyData$Age <- factor(surveyData$Age, levels = c("A", "J"), labels = c("Adult", "Juvenile"))
surveyData$Interval_1 <- ifelse(surveyData$Min_1 == "X", NA, surveyData$Min_1)
surveyData$Interval_2 <- ifelse(surveyData$Min_2 == "X", NA, surveyData$Min_2)
surveyData$Interval_3 <- ifelse(surveyData$Min_3 == "X", NA, surveyData$Min_3)
surveyData$Interval_4 <- ifelse(surveyData$Min_4 == "X", NA, surveyData$Min_4)
surveyData$Interval_5 <- ifelse(surveyData$Min_5 == "X", NA, surveyData$Min_5)
surveyData$Interval_6 <- ifelse(surveyData$Min_6 == "X", NA, surveyData$Min_6)
surveyData$Interval_7 <- ifelse(surveyData$Min_7 == "X", NA, surveyData$Min_7)
surveyData$Interval_8 <- ifelse(surveyData$Min_8 == "X", NA, surveyData$Min_8)
surveyData$Interval_9 <- ifelse(surveyData$Min_9 == "X", NA, surveyData$Min_9)
surveyData$Interval_10 <- ifelse(surveyData$Min_10 == "X", NA, surveyData$Min_10)
surveyData$Interval_11 <- ifelse(surveyData$Min_11 == "X", NA, surveyData$Min_11)
surveyData$Interval_12 <- ifelse(surveyData$Min_12 == "X", NA, surveyData$Min_12)
surveyData$Interval_1 <- factor(surveyData$Interval_1, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_2 <- factor(surveyData$Interval_2, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_3 <- factor(surveyData$Interval_3, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_4 <- factor(surveyData$Interval_4, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_5 <- factor(surveyData$Interval_5, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_6 <- factor(surveyData$Interval_6, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_7 <- factor(surveyData$Interval_7, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_8 <- factor(surveyData$Interval_8, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_9 <- factor(surveyData$Interval_9, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_10 <- factor(surveyData$Interval_10, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_11 <- factor(surveyData$Interval_11, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
surveyData$Interval_12 <- factor(surveyData$Interval_12, levels = c("C","S","V"), labels =
c("Calling", "Singing", "Visual"))
View(surveyData)
surveyData$dayOfYear <- yday(surveyData$Count_Date) # create a day-of-year variable for analysis
surveyData$surveyYear <- year(surveyData$Count_Date)
## Add a "first detected by..." column to survey data:
surveyData <-
surveyData %>%
filter(!is.na(Sex)) %>%
select(Sex, Lark_ID, Interval_1, Interval_2, Interval_3, Interval_4,
Interval_5, Interval_6, Interval_7, Interval_8, Interval_9,
Interval_10, Interval_11, Interval_12) %>%
pivot_longer(., cols = 3:32, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID, Sex) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(detection)) %>%
right_join(., surveyData, by = 'Lark_ID', keep = F) %>%
select(!(Sex.x)) %>%
rename(Sex = Sex.y)
## Add a "first detected by..." column to survey data:
surveyData <-
surveyData %>%
filter(!is.na(Sex)) %>%
select(Sex, Lark_ID, Interval_1, Interval_2, Interval_3, Interval_4,
Interval_5, Interval_6, Interval_7, Interval_8, Interval_9,
Interval_10, Interval_11, Interval_12) %>%
pivot_longer(., cols = 3:14, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID, Sex) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(detection)) %>%
right_join(., surveyData, by = 'Lark_ID', keep = F) %>%
select(!(Sex.x)) %>%
rename(Sex = Sex.y)
View(surveyData)
## Add a "first detected interval" column
surveyData <-
surveyData %>%
filter(!is.na(Sex)) %>%
select(Sex, Lark_ID, Interval_1, Interval_2, Interval_3, Interval_4,
Interval_5, Interval_6, Interval_7, Interval_8, Interval_9,
Interval_10, Interval_11, Interval_12) %>%
pivot_longer(., cols = 3:14, names_to = "interval", values_to = "detection") %>%
group_by(Lark_ID, Sex) %>%
filter(!is.na(detection)) %>%
summarise(firstDet = first(interval)) %>%
mutate(firstInterval = ifelse(firstDet == "Interval_1",1,
ifelse(firstDet == "Interval_2", 2,
ifelse(firstDet == "Interval_3", 3,
ifelse(firstDet == "Interval_4", 4,
ifelse(firstDet == "Interval_5", 5,
ifelse(firstDet == "Interval_6", 6,
ifelse(firstDet == "Interval_7", 7,
ifelse(firstDet == "Interval_8", 8,
ifelse(firstDet == "Interval_9", 9,
ifelse(firstDet == "Interval_10", 10,
ifelse(firstDet == "Interval_11", 11,
ifelse(firstDet == "Interval_12", 12,NA)))))))))))))%>%
right_join(., surveyData, by = 'Lark_ID', keep = F) %>%
select(!(Sex.x)) %>%
select(!firstDet.x) %>%
rename(firstDet = firstDet.y, Sex = Sex.y)
# calculate sunrise times at Corvallis Airport on each survey date.
sunriseTimes <- getSunlightTimes(date = surveyData$Count_Date, lat = 44.50, lon = -123.28,
keep = c("sunrise"), tz="America/Los_Angeles")
#create a new variable in surveyData that has sunrise matched to the survey point.
#careful, here, because there is no matching function (i.e., this only works if the
#two data frames are sorted in the same order. This should be the case unless you
#sort one after calling this function).
surveyData$sunrise <- sunriseTimes$sunrise
#subtract the two times to get decimal hours after sunrise.
surveyData$mas <- 60*((surveyData$Start_Time@hour + surveyData$Start_Time@minute/60) -
(hour(surveyData$sunrise) + minute(surveyData$sunrise)/60))
#clean up
rm(sunriseTimes)
##Write file to CSV for easier import to reporting markdown:
write_csv(surveyData, file = "/Users/johnlloyd/Documents/GitHub/hornedLarks/surveyData2025.csv")
surveyData <- read.csv(file = "/Users/johnlloyd/Documents/GitHub/hornedLarks/surveyData2025.csv",
header = TRUE,
sep = ",")
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
surveyData23 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
library(tidyverse)
library(readxl)
library(lubridate)
library(suncalc)
library(ggpmisc)
library(unmarked)
library(AICcmodavg)
library(ubms)
library(knitr)
library(kableExtra)
library(ggpmisc)
library(ubms)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
surveyData23 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
View(surveyData23)
surveyData23 <-
surveyData23 %>%
select(unique_ID, Survey_Date,Survey_Time,Interval_1, Interval_2,Interval_3,Interval_4)
surveyData24 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
View(surveyData24)
surveyData24 <-
surveyData24 %>%
select(unique_ID, OffRoad_ID,Survey_Date,Survey_Time,Min_1,Min_2,Min_3,Min_4,Min_5,Min_6,
Min_7,Min_8.Min_9.Min_10,Min_11,Min_12,Min_13,Min_14,Min_15,Min_16,Min_17,Min_18,
Min_19,Min_20,Min_21,Min_22,Min_23,Min_24)
surveyData24 <-
surveyData24 %>%
select(unique_ID, OffRoad_ID,Survey_Date,Survey_Time,Min_1,Min_2,Min_3,Min_4,Min_5,Min_6,
Min_7,Min_8,Min_9,Min_10,Min_11,Min_12,Min_13,Min_14,Min_15,Min_16,Min_17,Min_18,
Min_19,Min_20,Min_21,Min_22,Min_23,Min_24)
surveyData24 <-
surveyData24 %>%
mutate(site = ifelse(is.na(unique_ID),OffRoad_ID,unique_ID))
View(surveyData24)
surveyData23 <-
surveyData23 %>%
mutate(site == unique_ID)
surveyData23 <-
surveyData23 %>%
mutate(site = unique_ID)
surveyData23 <-
surveyData23 %>%
mutate(site = unique_ID) %>%
select(-unique_ID)
#Assign site identification, complicated by the use of OffRoad_ID as an equivalent of
#unique_ID for points not on roadside
surveyData24 <-
surveyData24 %>%
mutate(site = ifelse(is.na(unique_ID),OffRoad_ID,unique_ID)) %>%
select(-OffRoad_ID,unique_ID)
View(surveyData24)
surveyData24 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData24 <-
surveyData24 %>%
select(unique_ID, OffRoad_ID,Survey_Date,Survey_Time,Min_1,Min_2,Min_3,Min_4,Min_5,Min_6,
Min_7,Min_8,Min_9,Min_10,Min_11,Min_12,Min_13,Min_14,Min_15,Min_16,Min_17,Min_18,
Min_19,Min_20,Min_21,Min_22,Min_23,Min_24)
#Assign site identification, complicated by the use of OffRoad_ID as an equivalent of
#unique_ID for points not on roadside
surveyData24 <-
surveyData24 %>%
mutate(site = ifelse(is.na(unique_ID),OffRoad_ID,unique_ID)) %>%
select(-OffRoad_ID,-unique_ID)
View(surveyData24)
surveyData25 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
View(surveyData25)
surveyData25 <-
surveyData25 %>%
select(unique_ID,Survey_Date,Survey_Time,Min_1,Min_2,Min_3,Min_4,Min_5,Min_6,
Min_7,Min_8,Min_9,Min_10,Min_11,Min_12,Min_13,Min_14,Min_15,Min_16,Min_17,
Min_18,Min_19,Min_20,Min_21,Min_22,Min_23,Min_24) %>%
mutate(site = unique_ID) %>%
select(-unique_ID)
View(surveyData25)
surveyDataAll <- bind_rows(surveyData23,surveyData24,surveyData25, .id = "site")
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
surveyData23 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
surveyData23 <-
surveyData23 %>%
select(unique_ID, Survey_Date,Survey_Time,Interval_1, Interval_2,Interval_3,Interval_4)
surveyData23 <-
surveyData23 %>%
mutate(site = factor(unique_ID)) %>%
select(-unique_ID)
surveyData24 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_2024_11.20.24.csv")
surveyData24 <-
surveyData24 %>%
select(unique_ID, OffRoad_ID,Survey_Date,Survey_Time,Min_1,Min_2,Min_3,Min_4,Min_5,Min_6,
Min_7,Min_8,Min_9,Min_10,Min_11,Min_12,Min_13,Min_14,Min_15,Min_16,Min_17,Min_18,
Min_19,Min_20,Min_21,Min_22,Min_23,Min_24)
#Assign site identification, complicated by the use of OffRoad_ID as an equivalent of
#unique_ID for points not on roadside
surveyData24 <-
surveyData24 %>%
mutate(site = factor(ifelse(is.na(unique_ID),OffRoad_ID,unique_ID))) %>%
select(-OffRoad_ID,-unique_ID)
surveyData25 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_data_22_Sep_2025.csv")
surveyData25 <-
surveyData25 %>%
select(unique_ID,Survey_Date,Survey_Time,Min_1,Min_2,Min_3,Min_4,Min_5,Min_6,
Min_7,Min_8,Min_9,Min_10,Min_11,Min_12,Min_13,Min_14,Min_15,Min_16,Min_17,
Min_18,Min_19,Min_20,Min_21,Min_22,Min_23,Min_24) %>%
mutate(site = factor(unique_ID)) %>%
select(-unique_ID)
surveyDataAll <- bind_rows(surveyData23,surveyData24,surveyData25, .id = "site")
View(surveyDataAll)
# Review and organize data, changing formats and variable names as needed.
#surveyData <- read_xlsx("~/Documents/GitHub/hornedLarks/WV_SurveyOutput.xlsx")
surveyData23 <- read_csv("~/Documents/GitHub/hornedLarks/WV_SHLA_22_23.csv")
surveyData23 <-
surveyData23 %>%
select(unique_ID, Survey_Date,Survey_Time,Interval_1, Interval_2,Interval_3,Interval_4)
surveyData23 <-
surveyData23 %>%
mutate(site = factor(unique_ID),
Min_1 = Interval_1,
Min_2 = Interval_2,
Min_3 = Interval_3,
Min_4 = Interval_4) %>%
select(-unique_ID,-Interval_1,-Interval_2,
-Interval_3, -Interval_4)
View(surveyData23)
surveyDataAll <- bind_rows(surveyData23,surveyData24,surveyData25, .id = "site")
View(surveyDataAll)
surveyDataAll <- bind_rows(surveyData23,surveyData24,surveyData25)
View(surveyDataAll)
